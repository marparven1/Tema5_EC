---
title: "Hoja 7 de problemas y prácticas con R"
author: "Marta Venegas Pardo"
subtitle: Tema 5: Métodos estadísticos de remuestreo
output:
  pdf_document: 
    toc: yes
    toc_depth: 3
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
```

# Ejercicio 1 Contraste bootstrap unilateral

1. Realizar un contraste bootstrap unilateral de hipótesis para comparar las desviaciones típicas a partir de las siguientes muestras:

- x=c(137.9, 143, 143.2, 140, 140.2, 139.3, 141.4, 140.1, 142, 137.2, 139.5, 142.7, 141.3) 
- y=c(141.6, 138.9, 140, 141.9, 140.5, 138.6, 141.5, 141.5, 140.7, 141.5, 140.4, 142,141)

\[H_0: \sigma_1 \leq \sigma_2\]

Escribir las instrucciones R sin y con la librería boot.

## Parte 1 (Contraste Bootstrap unilateral)

```{r}
x<-c(137.9, 143, 143.2, 140, 140.2, 139.3, 141.4, 140.1, 142, 137.2, 139.5, 142.7, 141.3)
y<-c(141.6, 138.9, 140, 141.9, 140.5, 138.6, 141.5, 141.5, 140.7, 141.5, 140.4, 142,141)
nx<-length(x)
ny<-length(y) 
boxplot(x,y,col=c("blue","red"))
```



```{r}
xy<-c(x,y)
nxy<-length(xy)
```


```{r}
B<-1999
set.seed(125)
T0<-sd(x)/sd(y)
T0
```


```{r}
Tast<-numeric(B) 
for (b in 1:B)
  Tast[b]<-sd(sample(xy,nx,replace=TRUE))/sd(sample(xy,ny,replace=TRUE))

hist(Tast,br=30,col="lightblue",prob=TRUE, 
     main=paste(B,"muestras bootstrap"),
     xlab="T*",ylab="")
abline(v=T0, lwd=4,col="red")
```


```{r}
cat("p valor bootstrap unilateral (>) = ",(sum(Tast>=T0)+1)/(B+1),"\n")
# Tast>=T0 Cuántas veces el estimador T asterisco es mayor que T0
```

Es menor que 0.05, por lo que rechazo $H_0$

## Paso 2 (bilateral)


Como tenemos cantidades positivas mayores que uno, es una buena opción para 
aplicar logaritmo.

```{r}
#Para un contraste bilateral se puede trabajar con log(sd(x)/sd(y))
hist(log(Tast),br=30,col="lightblue",
     prob=TRUE, main=paste(B,"muestras bootstrap"),
     xlab="log(T*)",ylab="")
abline(v=log(T0), lwd=4,col="red")
cat("p valor bootstrap unilateral (>) = ",(sum(log(Tast)>=log(T0))+1)/(B+1),"\n")
abline(v=-log(T0), lwd=4,col="red")
```


```{r}
cat("p valor bootstrap bilateral = ", 
    (sum(abs(log(Tast))>=abs(log(T0)))+1)/(B+1),"\n")
```


Acepto $H_0$

## Parte 3 (Con la librería boot)

```{r}
library(boot) 
cocboot=function(xy,indi,nx) {
  sd(xy[indi[1:nx]])/sd(xy[indi[-c(1:nx)]]) 
  }
resulboot=boot(xy,cocboot,nx=nx,R=1999) 
hist(resulboot$t,br=30,col="lightblue",prob=TRUE,
     main=paste(B,"muestras bootstrap"),
     xlab="T*",ylab="") 
abline(v=resulboot$t0, lwd=4,col="red")
```


```{r}
cat("p valor bootstrap unilateral (>) = ",
    (sum(resulboot$t>=resulboot$t0)+1)/(B+1),"\n")
```

P-valor muy pequeño, rechazo $H_0$

```{r}
T0
```

```{r}
resulboot$t0
```


```{r}
summary(Tast)
```



```{r}
summary(resulboot$t)
```


```{r}
cat("p valor bootstrap bilateral = ", (sum(abs(log(resulboot$t))>=abs(log(resulboot$t0)))+1)/(B+1),"\n")
```


# Ejercicio 2 Contraste de hipótesis unilateral

2. Realizar mediante procedimientos bootstrap el contraste de hipótesis unilateral relativo a la posibilidad de que la primera componente principal del fichero iris de R explique más del 70% de la varianza total. Hacerlo directamente y con la ayuda de **boot**.

## ACP

```{r}
#Porcentaje de varianza explicada por la primera C.P. 
##?Puede aceptarse que es superior al 70%? 

##H0:PE1<=70; H1:PE1>70
set.seed(357)
data(iris) #?iris
```


```{r}
ACP<- princomp(iris[,-5],cor=T)
summary(ACP)
```


```{r}
ACP$loadings
```


```{r}
varcp<- ACP$sdev^2 
sum(varcp)
```


```{r}
PE1_0<- 100*varcp[1]/sum(varcp) 
dife0<- PE1_0-70
n<-nrow(iris)
indices<- 1:n

B<- 4999
difeBoot<- numeric(B)
for (i in 1:B)
  { if (i%%500==0) cat("Muestra bootstrap ",i,"\n")
  ACPBoot<- princomp(iris[sample(indices,rep=T),-5],cor=T) 
  varcpboot<- ACPBoot$sdev^2
  PE1Boot<- 100*varcpboot[1]/sum(varcpboot)
  difeBoot[i]<- PE1Boot-PE1_0 
  }
```

## Histograma y p-valor

```{r}
hist(difeBoot,br=30, # 30 intervalos
     col="lightblue",prob=TRUE, 
    main=paste(B,"muestras bootstrap"),
    xlab="PE1*-PE1",ylab="")
abline(v=dife0, lwd=4,col="red")
```



```{r}
cat("p valor bootstrap unilateral (>) = ", 
     (sum(difeBoot>=dife0)+1)/(B+1),"\n")
```

## Con librería BOOT

```{r}
library(boot) 
calculoPE1boot=function(datos,indi) {
  ACPBoot<- princomp(iris[indi,-5],cor=T) 
  varcpboot<- ACPBoot$sdev^2
  PE1<- 100*varcpboot[1]/sum(varcpboot)
  PE1 
  }
resulboot=boot(iris,calculoPE1boot,R=4999)
```


```{r}
hist(resulboot$t-resulboot$t0, # hacemos la diferencia a la hora de representar
     br=30,
     col="lightblue",
     prob=TRUE, 
     main=paste(B,"muestras bootstrap (boot)"),
     xlab="PE1*-PE1",ylab="")
abline(v=resulboot$t0-70, lwd=4,col="red")
```





# Ejercicio 3 IC bootstrap para un cociente

3. Las siguientes instrucciones permiten definir dos variables en R que contienen las medidas de la corrosión (y) en 13 aleaciones de níquel-cobre, cada una de ellas con un contenido de hierro x. Es de interés el cambio en la corrosión cuando aumenta el nivel de hierro, comparado con la pérdida de corrosión cuando no hay hierro: $\beta_1 / \beta_0$ en el modelo de regresión lineal.

Calcular intervalos de confianza bootstrap para dicho cociente.

- x<- c(0.01,0.48,0.71,0.95,1.19,0.01,0.48,1.44,0.71,1.96,0.01,1.44,1.96)
- y<- c(127.6,124,110.8,103.9,101.5,130.01,122,92.3,113.1,83.7,128,91.4,86.2)


Se sabe que un estimador de la varianza de $\beta_1 / \beta_0$ mediante el método delta es: 


\[ \Bigg( \dfrac{\hat\beta_1}{\hat\beta_0} \Bigg)^2 \quad \Bigg( \dfrac{\hat v(\hat\beta_1)}{\hat\beta_1^2} + \dfrac{\hat v(\hat\beta_0)}{\hat\beta_0^2} - \dfrac{2cov(\hat\beta_0,\hat\beta_1)}{\hat\beta_0 \hat\beta_1} \Bigg)
\]


La función utilizada para calcular el estadístico de interés debe incluir también esta estimación de su varianza, para usarla en el método bootstrap-t.



```{r}
x<- c(0.01,0.48,0.71,0.95,1.19,0.01,0.48,1.44,0.71,1.96,0.01,1.44,1.96)
y<- c(127.6,124,110.8,103.9,101.5,130.01,122,92.3,113.1,83.7,128,91.4,86.2)
cor(x,y)
```



```{r}
plot(x,y,xlab="HIERRO",ylab="CORROSION",main="") 
regrelin<- lm(y~x)
summary(regrelin)
abline(regrelin,col="red",lwd=2)
```

```{r}
coefici<- coef(regrelin) 
print(T0<- coefici[2]/coefici[1])
```


```{r}
alfa<-0.05
xydat<- data.frame(x,y)
library(boot)
#Para bootstrap de pares 

calcuT<-function(xydat,indi)
  {
  regre<-lm(y~x,data=xydat[indi,])
  coefi<- regre$coefficients
  T<-coefi[2]/coefi[1]
  V<-vcov(regre) #cov(beta0,beta1)
  auxi<- (V[1,1]/(coefi[1]^2)) + (V[2,2]/(coefi[2]^2))- 
    2*V[1,2]/(coefi[1]*coefi[2])
  varT<- (T^2) * auxi #var(T), método delta para bootstrap stud (t) 
  c(T,varT)
}

Tbootpares<-boot(xydat,calcuT,1000) #Datos, estadístico, B

hist(Tbootpares$t[,1],br=30,main="Bootstrap de pares", col="red",xlab="T*")
```
```{r}
boot.ci(Tbootpares, conf=1-alfa, type=c("norm","perc","stud","bca"), 
        var.t = Tbootpares$t[,2]) # a boot.ci le paso lo que me ha devuelto 
# la función boot
```



```{r}
#Bootstrap de residuos
calcuTres<-function(xydat,indi)
  { xydat$y<- predict(regrelin)+residuals(regrelin)[indi]
  regre<-lm(y~x,data=xydat) 
  coefi<- regre$coefficients 
  T<-coefi[2]/coefi[1] 
  V<-vcov(regre)
  auxi<- (V[1,1]/(coefi[1]^2)) + (V[2,2]/(coefi[2]^2))-
    2*V[1,2]/(coefi[1]*coefi[2])
  varT<- (T^2) * auxi #var(T), m?todo delta para bootstrap stud (t) c(T,varT)
}
```


```{r}
Tbootresi<-boot(xydat,calcuTres,1000)
```


```{r}
hist(Tbootresi$t[,1],br=30,main="Bootstrap de residuos", col="red",xlab="T*")
```


```{r}
#boot.ci(Tbootresi, 
#        conf=1-alfa,
#        type=c("norm","perc","stud","bca"), 
#        var.t = Tbootresi$t[,2])
```












# Ejercicio 4 IC bootstrap (Modelo Beverton-Holt)
4. El fichero “salmon.dat” contiene datos anuales sobre una población de salmones. 

Las variables que aparecen son: 

- R = “recruits” número de salmones que entran
- S = “spawners” número de salmones que están poniendo huevos, que mueren en cuanto lo hacen. 

Para que la población se estabilice se requiere: R = S (en otro caso, o hay demasiados salmones para los mismos recursos, o bien no se repone la población).


Se desea calcular un I.C. bootstrap para el punto donde R = S, trabajando con el modelo de Beverton-Holt:

\[R = \dfrac{1}{\beta_0 + \beta_1/s}\]



```{r}
#Se desea calcular un I.C. para el punto donde R=S

salmon<- read.table("datos/salmon.dat",header=T) #acceso a los datos salmon
salmon %>% head()
```

```{r}
attach(salmon) 
plot(R,S,main="Datos salmon") # Dibujamos la nube de puntos

regre1<- lm(S~R) # Modelo de regresión lineal
summary(regre1) 
abline(regre1,col="red")
```

Vemos que el ajuste no es malo, $R^2$= 0.89. Retenemos casi un 90% de la variabilidad total del experimento.

```{r}
plot(1/R,1/S,main="Datos salmón. Transformac. inversa")
```
```{r}
rt<- 1/R
st<- 1/S
regre2<- lm(st~rt) #Modelo de Beverton-Holt 
summary(regre2)
```

Vemos que para el modelo inverso, el $R^2$ es mucho más alto. Casi un 99%.

La correlación:

```{r}
cor(R,1/predict(regre2))^2
```

Muy alta.

```{r}
plot(R,S,main="Datos Salmon. Modelo de Beverton-Holt") 
points(R,1/predict(regre2),col="red")
#Punto de estabilizac., resolviendo en el modelo 1/R=prediccion(R)
coefi<- coef(regre2)
Restab0<-(1-coefi[2])/coefi[1]
c(Restab0,1/predict(regre2,data.frame(rt=1/Restab0)))

points(Restab0,Restab0,col="green",lwd=8) 
#lines(Restab,Restab,lty=2,type="h",col="grey") Equivale a la siguiente 
segments(x0=Restab0, y0=0, x1 = Restab0, y1 = Restab0,lty=2,col="grey") 
segments(0, Restab0, Restab0, Restab0,lty=2,col="grey")
grid()
```


Intervalo de confianza bootstrap:



```{r}
# Bootstrap
alfa=0.05 

calcuRestabpares<-function(xydat,indi)
{coefi<- lsfit(xydat[indi,1],xydat[indi,2])$coefficients 
  (1-coefi[2])/coefi[1]
}

library(boot)
xydat<- data.frame(rt,st)
##bootstrap de pares
bootpares<-boot(xydat,calcuRestabpares,2000) #Datos, estadístico, B 
Restabastepares<-c(bootpares$t) #Lo de c() para que no sea matriz
hist(Restabastepares,br=30,main="R establizac., B. pares", col="red")
```

```{r}
ICbootpares<- boot.ci(bootpares, conf=1-alfa, t=Restabastepares,t0=Restab0,
                      type=c("norm","perc","bca"))
```


```{r}
##Bootstrap de residuos
calcuRestabresid<-function(xydat,indi) {
  coefi<-lsfit(xydat[,1], predict(regre2)+(residuals(regre2)[indi]))$coefficients
  (1-coefi[2])/coefi[1] 
}

bootresi<-boot(xydat,calcuRestabresid,2000) 
Restabasteresid<-c(bootresi$t)
```


```{r}
hist(Restabasteresid,br=30,main="R establizac., B. residuos", col="red")
```
Por último, el IC bootstrap

```{r}
ICbootresid<- boot.ci(bootresi, 
                      conf=1-alfa, 
                      t=Restabasteresid,
                      t0=Restab0,
                      type=c("norm","perc","bca"))
ICbootresid
```


```{r}
ICbootpares
```



```{r}
#Estimac. corrigiendo el sesgo y estimac. de la varianza
sesgoB<- mean(Restabasteresid)-Restab0 
Rcorreg<-Restab0-sesgoB 
sd(Restabasteresid)
```



```{r}
#IC normal
c(Rcorreg-qnorm(1-alfa/2)*sd(Restabasteresid), 
  Rcorreg+qnorm(1-alfa/2)*sd(Restabasteresid))
```


# Ejercicio 5
5. Diseñar un estudio empírico para analizar la efectividad de la transformación Z de Fisher en el cálculo de intervalos de confianza para el coeficiente de correlación lineal poblacional. 

Por ejemplo, generar 100 muestras de tamaño 10 de una Normal bivariante de media 0, desviaciones típicas 1 y correlación 0.6 y calcular los I.C. al 95% con los métodos Percentil, Normal y BCa. Comparar los cubrimientos y las longitudes medias utilizando procedimientos numéricos y gráficos.



```{r}
#5. Estudio la efectividad de la transformac. Z de Fisher
library(MASS) #para mvrnorm library(boot)
z.transform <- function(r) {.5*log((1+r)/(1-r))} 
z.inversa <- function(z) (exp(2*z)-1)/(exp(2*z)+1) 

cor.fun <- function(datos,i1,i2, indices) {
  x <- datos[indices,i1]
  y <- datos[indices,i2]
  cor(x, y)
  } #r directamente

zcor.fun <- function(datos,i1,i2, indices) {
  x <- datos[indices,i1]
  y <- datos[indices,i2]
z.transform(cor(x, y))
} #Con transf. Z de Fisher
```


```{r}
set.seed(13579)
M<- 100 #número de muestras, en la práctica se tomaría M=10000 
n<-10 #tamaño muestral
pho<- 0.6
correl<- numeric(M)
Zcor<- numeric(M) 
InterPerc<- matrix(NA,M,2) 
InterNorm<- matrix(NA,M,2) 
InterBca<- matrix(NA,M,2) 
InterPercZ<- matrix(NA,M,2)
InterNormZ<- matrix(NA,M,2) 
InterBcaZ<- matrix(NA,M,2)

for (i in 1:M)
  { if (i%%10==0) cat("Muestra ",i,"\n")
xy<-data.frame(mvrnorm(n, c(0,0), matrix(c(1,pho,pho,1),2,2)))
correl[i]<- cor(xy)[1,2]
xy.boot1 <- boot(xy, cor.fun, i1=1,i2=2, R=999)
xy.boot2 <- boot(xy, zcor.fun,i1=1,i2=2, R=999) 
InterPercZ[i,]<-z.inversa(boot.ci(xy.boot2, type="perc")$percent[4:5])
InterNormZ[i,]<-z.inversa(boot.ci(xy.boot2, type="norm")$normal[2:3]) 
InterBcaZ[i,]<-z.inversa(boot.ci(xy.boot2, type="bca")$bca[4:5]) 
InterPerc[i,]<-boot.ci(xy.boot1, type="perc")$percent[4:5] 
InterNorm[i,]<-boot.ci(xy.boot2, type="norm")$normal[2:3]
InterBca[i,]<-boot.ci(xy.boot2, type="bca")$bca[4:5]
}
```


```{r}
Zcorrel<-z.transform(correl)
```


```{r}
hist(correl,br=20,
main=paste(M,"muestras. Coeficiente de correlac."),col="lightblue")
```
```{r}
hist(Zcorrel,
     br=20,
     main=paste(M,"muestras. Transf. Z del Coeficiente de correlac."), 
     cex.main=0.8,col="lightblue")
```
```{r}
#Como se sabe que r toma valores en [-1,1]:
corrige<- function(x) {
if (x[1]< -1)  x[1]= -1 
if (x[2]> 1) x[2]= 1
x
} 
InterPercZ<-t(apply(InterPercZ,1,corrige)) 
InterNormZ<-t(apply(InterNormZ,1,corrige))
InterBcaZ<-t(apply(InterBcaZ,1,corrige)) 
InterPerc<-t(apply(InterPerc,1,corrige)) 
InterNorm<-t(apply(InterNorm,1,corrige)) 
InterBca<-t(apply(InterBca,1,corrige))
```


```{r}
#Función para calcular la cobertura y
#la longitud de un conjunto de intervalos 
rendimiento<- function(x,pho){
  cubri<-mean(apply(x,1,cubre<-function(a) { pho<=a[2] && pho>= a[1]} ))*100 
  longi<-mean(x[,2]-x[,1])
  c(cubri,longi)
  } 
Resultados<-matrix(c(rendimiento(InterPerc,pho),
                     rendimiento(InterNorm,pho),
                     rendimiento(InterBca,pho), 
                     rendimiento(InterPercZ,pho), 
                     rendimiento(InterNormZ,pho), 
                     rendimiento(InterBcaZ,pho)),byrow=T,6,2)

colnames(Resultados)<- c("Cubrimiento","Long.Media")
rownames(Resultados)<- c("Percentil","Normal","Bca", "PercentilZ","NormalZ","BcaZ")
Resultados
```

```{r}
plot(Resultados,type="n",
     main="Resultados del experimento",xlim=c(90,96))
text(Resultados,labels=rownames(Resultados), col=c(rep("blue",3),rep("red",3)))
grid()
```



```{r}
#Longitudes de los intervalos, y diferencias #según se aplique o no la transf.Z 
longiPerc<- InterPerc[,2]-InterPerc[,1]
longiPercZ<- InterPercZ[,2]-InterPercZ[,1] 
difePerc<- longiPerc-longiPercZ
longiNorm<- InterNorm[,2]-InterNorm[,1]
longiNormZ<- InterNormZ[,2]-InterNormZ[,1]
difeNorm<- longiNorm-longiNormZ
longiBca<- InterBca[,2]-InterBca[,1]
longiBcaZ<- InterBcaZ[,2]-InterBcaZ[,1] 
difeBca<- longiBca-longiBcaZ 
boxplot(difePerc,difeNorm,difeBca)
```

## Contrastes

Para cada una de las M muestras se han aplicado diversos métodos.

### Muestras relacionadas

Las posibles comparaciones corresponden a muestras relacionadas

```{r}
t.test(difePerc)
```

```{r}
t.test(difeNorm)
```

```{r}
t.test(difeBca)
```


Para comparar las proporciones: 

Aquí habría que aplicar Test de Mcnemar por el mismo motivo de muestras relacionadas

```{r}
#Primero se construyen tablas cruzando la cobertura (T/F) de cada método
CubPerc=apply(InterPerc,1,cubre<-function(a) { pho<=a[2] && pho>= a[1]} )
CubPercZ=apply(InterPercZ,1,cubre<-function(a) { pho<=a[2] && pho>= a[1]} )
CubNorm=apply(InterNorm,1,cubre<-function(a) { pho<=a[2] && pho>= a[1]} )
CubNormZ=apply(InterNormZ,1,cubre<-function(a) { pho<=a[2] && pho>= a[1]} )
CubBca=apply(InterBca,1,cubre<-function(a) { pho<=a[2] && pho>= a[1]} ) 
CubBcaZ=apply(InterBcaZ,1,cubre<-function(a) { pho<=a[2] && pho>= a[1]} )
```


```{r}
( TablaPerc=table(CubPerc,CubPercZ) )
```



```{r}
mcnemar.test(TablaPerc)
```
Aceptamos la hipótesis nula.

```{r}
#H0:P[T/No Z]=P[T/Z]
( TablaNorm=table(CubNorm,CubNormZ) )
```

```{r}
mcnemar.test(TablaNorm)
```


Volvemos a aceptar


```{r}
( TablaBca=table(CubBca,CubBcaZ) )
```


```{r}
mcnemar.test(TablaBca)
```

Para esta tabla acepto de nuevo.

### Muestras independientes

Nota: Si las muestras fueran distintas para los diferentes métodos, muestras independientes:

```{r}
prop.test(Resultados[c(1,4),1], c(M,M))
```


```{r}
prop.test(Resultados[c(2,5),1], c(M,M))
```
```{r}
prop.test(Resultados[c(3,6),1], c(M,M))
```





```{r}
#En este caso, si hay avisos, #usar el test exacto de Fisher
totales<- Resultados[,1]*M/100
mcnemar.test(matrix(c(totales[1], 
                      M-totales[1],
                      totales[4],
                      M-totales[4]),
                    byrow=T,ncol=2))
```


```{r}
fisher.test(matrix(c(totales[1],
                     M-totales[1],
                     totales[4],
                     M-totales[4]), 
                   byrow=T,ncol=2),alternative="greater")
```


```{r}
fisher.test(matrix(c(totales[2], M-totales[2],totales[5],M-totales[5]), 
                   byrow=T,ncol=2),alternative="greater")
```


```{r}
fisher.test(matrix(c(totales[3], M-totales[3],totales[5],M-totales[5]), 
                   byrow=T,ncol=2),alternative="greater")
```


## Gráficas de los IC

### Percentil
```{r}
#Dibujo de los I.C. Percentil
plot(InterPerc[,1],ylim=c(-1,1),type="l",
main="IC-Bootstrap (Percentil)",col="red",xlab="Muestra", ylab="")
lines(InterPerc[,2],col="red") 
lines(InterPercZ[,1],col="blue",lty=2) 
lines(InterPercZ[,2],col="blue",lty=2)
legend("bottomright",col=c("red","blue"), lty=1:2, 
       legend=c("Sin transf. Z","Con transf. Z de Fisher"))
abline(h=pho,lwd=2) 
abline(h=1,lty=2);abline(h=-1,lty=2); grid()
```



### Normal
```{r}
#Dibujo de los I.C. Normal
plot(InterNorm[,1],ylim=c(-1,1),type="l", main="IC-Bootstrap (Normal)",
     col="red",xlab="Muestra", ylab="") 
lines(InterNorm[,2],col="red") 
lines(InterNormZ[,1],col="blue",lty=2)
lines(InterNormZ[,2],col="blue",lty=2)
legend("bottomright",col=c("red","blue"), lty=1:2, legend=c("Sin transf. Z","Con transf. Z de Fisher")) 
abline(h=pho,lwd=2)
abline(h=1,lty=2);abline(h=-1,lty=2); grid()
```


### BCa

```{r}
#Dibujo de los I.C. BCa
plot(InterBca[,1],ylim=c(-1,1),type="l", main="IC-Bootstrap (BCa)",
     col="red",xlab="Muestra", ylab="")
lines(InterBca[,2],col="red") 
lines(InterBcaZ[,1],col="blue",lty=2)
lines(InterBcaZ[,2],col="blue",lty=2) 
legend("bottomright",col=c("red","blue"), lty=1:2,
       legend=c("Sin transf. Z","Con transf. Z de Fisher")) 
abline(h=pho,lwd=2) 
abline(h=1,lty=2);abline(h=-1,lty=2); grid()
```


Los basados en la transformac., en generaltienen menor longitud, y el extremo superior es <1.

# Ejercicio 6 Sesgo de la razón (de medias) Bootstrap balanceado

6. Estimar el sesgo de la razón (cociente de las medias de las variables x y u) en el fichero “city” de R mediante el bootstrap balanceado (fichero disponible en la librería “boot”):

## a. Escribiendo directamente las instrucciones.


```{r}
library(boot)
data(city)
city
```

```{r}
# ?city
```

La razón será:

```{r}
print(R<- mean(city$x)/mean(city$u) )
```

```{r}
B<- 999
Raste<- numeric(B) 
n<- nrow(city) 
lista<- rep(1:n,B) 
table(lista)
```

```{r}
listaper<- matrix(sample(lista),ncol=n,byrow=TRUE)
head(listaper)
```


```{r}
tail(listaper)
```


```{r}
for (b in 1:B) 
{indiB<-listaper[b,]
  Raste[b]<- mean(city$x[indiB])/mean(city$u[indiB])
  }
hist(Raste)
```


```{r}
mean(Raste)-R
```

## b. Empleando la librería boot.


```{r}
ratio <- function(d,indi) mean(d$x[indi])/mean(d$u[indi])
boot.bal<- boot(data=city, statistic=ratio, R = 999, sim="balanced")
mean(boot.bal$t)-boot.bal$t0
```

El resultado es el mismo y sale más directo.


\newpage

# Ejercicio 7 Estimar el error de clasificación

7. Estimar el error de clasificación para el modelo de análisis discriminante lineal sobre los datos “cats” de la librería MASS.

```{r}
library(MASS)
data(cats)
summary(cats)
```


Vamos a aplicar análisis discriminante lineal.


```{r}
#?cats
colores<- c("red","blue")
plot(cats[,2:3],type="n",main="Datos Cats")
text(cats[,2:3],as.character(cats$Sex),
          col=colores[cats$Sex],cex=0.6)

grid()
```
Hemos podido discriminar y ver a que categoría pertenecen, no va  a ser un modelo perfecto y vamos a cometer errores probablemente.


Para obtener los datos del modelo discriminante (función lda)

```{r}
cats.lda<-lda(Sex~.,cats)
cats.lda
```


En LD1 está la línea que separa a las categorías.

```{r}
table(cats$Sex,predict(cats.lda)$class)
# g_{lambda}(li)=predict(cats.lda)$class
```

Se tiene que: 

- Aciertos: Diagonal
- Errores: diagonal opuesta



```{r}
erroremp<- mean(cats$Sex!=predict(cats.lda)$class)
# Número de unos / número total de observaciones
cat("Error empírico=",100*erroremp ,"% \n")
# Error empírico ó error de entrenamiento
```

```{r}
#lda admite CV=TRUE que implementa n-VC (calcula el error esperado del modelo)
##o sea, Jackknife 
cats.ldaJ<-lda(Sex~.,cats,CV=TRUE)
str(cats.ldaJ)
```

Vamos a calcular el error de predicción:


```{r}
table(cats$Sex,cats.ldaJ$class)
```





```{r}
errorJ<- mean(cats$Sex!=cats.ldaJ$class)
cat("Error Jackknife=",100*errorJ ,"% \n")
```

Generar muestras bootstrap de conjuntos de datos.


```{r}
#Cómo se generan muestras bootstrap de conjuntos #de datos. Por ejemplo 
datos=cats[c(1:5,140:144),]
datos
```



```{r}
datos[sample(1:nrow(datos),rep=TRUE),]
```





Vamos a crear muestras bootstrap

```{r}
#Estimaciones Bootstrap:
########################
B<- 2000 # Construyo 2000 muestras bootstrap
errorboot<-numeric(B) 
errorOOB<- numeric(B) 
n<- nrow(cats) 
indin<- 1:n
for (b in 1:B)
{
if (b%%500==0) 
  cat("Muestra bootstrap número ",b,"\n") #Generar muestra bootstrap de los indices
indiB<- sample(indin,rep=T) # muestra de entrenamiento
# los datos que no esten en la muestra de entrenamiento serán los datost
#Obtener los ?ndices no incluidos en imuestrab 
indiOOB<-setdiff(indin,indiB) # La diferencias (los que no han salido)
  #Construir modelo lda sobre la muestra bootstrap
cats.lda.boot<-lda(Sex~.,cats[indiB,])
#Calcular tasa de error en la muestra original
errorboot[b]<- mean(cats$Sex!=predict(cats.lda.boot,cats)$class)  # error
#Obtener predicciones OOB
prediOOB<- predict(cats.lda.boot,cats[indiOOB,])$class # predicciones sobre las observaciones no elegidas
#Calcular la tasa de error OOB
errorOOB[b]<- mean(cats$Sex[indiOOB]!=prediOOB)
}
```



```{r}
errorB<- mean(errorboot) #no recomendable
errorB
```
```{r}
errorOOB<- mean(errorOOB) 
error632B<-0.368*erroremp+0.632*errorOOB
```





```{r}
#Calcular cada elemento Lij #directamente:
matrizL<- matrix(NA,n,n) 
for (i in 1:n)
for (j in 1:n)
matrizL[i,j]<- (cats[i,]$Sex!=predict(cats.lda,cats[j,])$class)
print(Noinf<- mean(matrizL))
```



```{r}
#O bien, en un problema de clasificación, #con error 0-1,
# Noinf se puede calcular #de forma más eficiente:
p1<- mean(cats$Sex=="M")
q1<- mean(predict(cats.lda)$class=="M") 
p1*(1-q1)+(1-p1)*q1
```


```{r}
#Redefinición de errorOOB (aquí no hace falta)
errorOOB
```





```{r}
Noinf
```


```{r}
erroremp
```




```{r}
errorOOB=min(errorOOB,Noinf) 
errorOOB
```


```{r}
#Cálculo de tsr y w
(tsr<- (errorOOB-erroremp)/(Noinf-erroremp))
```


```{r}
(w<- 0.632/(1-0.368*tsr))
```


```{r}
 #Posible redefinición de tsr
if ( (errorOOB<= erroremp) | (Noinf <=erroremp) ) # en alguno de estos casos sedará la correción
  tsr=0 
tsr
```


```{r}
#(error632masB<-(1-w)*erroremp+w*errorOOB)
# #Definición general (la línea anterior no vale #si se redefinen tsr o errorOOB)
error632masB=error632B+
  (errorOOB-erroremp)*(0.368*0.632*tsr)/(1-0.368*tsr) 

error632masB
```


```{r}
op_ant = options(digits=4)
cat(" Error Empírico=\t",100*erroremp ,"% \n",
"Error Jackknife=\t",100*errorJ ,"% \n",
"Error OOB=\t\t", 100*errorOOB,"% \n",
"Error 0.632Boot=\t", 100*error632B,"% \n",
"Error 0.632+Boot=\t", 100*error632masB,"% \n")
```


```{r}
options(op_ant)
```

\newpage




# Ejercicio 8 Error de predicción (criterio RECM)

8. Estimar el error de predicción para los datos “Renta.txt”, siendo “rentsqm” (precio del alquiler por m2) la variable dependiente de un modelo de regresión lineal.
Utilizar el criterio RECM.

## Parte 1 Leer datos

ESTIMACION DEL ERROR DE PREDICCION (REGRESION)

```{r}
datos<-read.table("datos/Renta.txt",header=T) 
dim(datos)
```


```{r}
summary(datos)
```


## Parte 2 (Modelo de regresión lineal múltiple)

```{r}
modelo=lm(rentsqm~.,data=datos) 
#Calcular MSE y RMSE empírico 
error_emp=mean(residuals(modelo)^2) 
RMSE_emp=sqrt(error_emp)
```




## Parte 3 (Estimaciones Jackknife y bootsrap)


### Jacknife

Se pueden calcular con cv.lm o bien recorriendo los n modelos cada uno se construye dejando fuera el caso i, donde se aplica el modelo para calcular prediJ[i].

```{r}
n=nrow(datos)
prediJ = numeric(n)
for(i in 1:n){
modelo.i = lm(rentsqm~.,data=datos[-i,]) 
prediJ[i]<-predict(modelo.i,datos[i,])
}

resi_J=datos$rentsqm - prediJ 
RMSE_J<-sqrt( mean(resi_J^2) )
```



## Parte 4 (generamos las muestras bootstrap)

### Bootstrap

Se pueden calcular los estimadores de ECM (MSE) y al final visualizar su raíz cuadrada.

```{r}
B<-2000
errorboot<-numeric(B)
errorOOB<- numeric(B)
indin<-1:n

for(b in 1:B){
if (b%%500==0) cat("Muestra bootstrap número ",b,"\n")
#Generar muestra bootstrap de los índices
indiB<- sample(indin,rep=T)
#Obtener los índices no incluidos en imuestrab
indiOOB<-setdiff(indin,indiB)
#Construir modelo lda sobre la muestra bootstrap
modelo.boot<-lm(rentsqm~.,data=datos[indiB,])
#Calcular ECM en la muestra original
suppressWarnings({ errorboot[b]<- mean((datos$rentsqm[indiB]-predict(modelo.boot,datos))^2)})
 #Obtener predicciones OOB
suppressWarnings({ prediOOB<- predict(modelo.boot,datos[indiOOB,]) })
#Calcular ECM OOB
errorOOB[b]<- mean((datos$rentsqm[indiOOB]-prediOOB)^2)
}
```


Y los errores:

```{r}
errorB<- mean(errorboot)
errorOOB<- mean(errorOOB) 
error632B<-0.368*error_emp+0.632*errorOOB
```


Calcular cada elemento L_ij. Al no ser un problema de clasificación, se debe calcular directamente: 


```{r}
matrizL<- matrix(NA,n,n)
for (i in 1:n)
for (j in 1:n)
matrizL[i,j]<- (datos$rentsqm[i]-predict(modelo,datos[j,]))^2 #error cuad.
print(Noinf<- mean(matrizL))
```


Redefinición de errorOOB (por si hiciera falta) 

```{r}
errorOOB #Noinf< error_emp ?
```


```{r}
Noinf
```


```{r}
errorOOB=min(errorOOB,Noinf) 
errorOOB
```


```{r}
 #Cálculo de tsr y w
(tsr<- (errorOOB-error_emp)/(Noinf-error_emp))
```


```{r}
(w<- 0.632/(1-0.368*tsr))
```







```{r}
#Posible redefinición de tsr
if ( (errorOOB<= error_emp) | (Noinf <= error_emp) ) 
tsr=0 
tsr
```




```{r}
#(error632masB<-(1-w)*erroremp+w*errorOOB) 
##Definición general (la línea anterior no vale 
###si se redefinen tsr o errorOOB) 

error632masB=error632B+
(errorOOB-error_emp)*(0.368*0.632*tsr)/(1-0.368*tsr)
error632masB
```



```{r}
cat(" RMSE Empírico=\t",sqrt(RMSE_emp), "\n",
" RMSE Jackknife=\t", RMSE_J, "\n",
" RMSE OOB=\t\t", sqrt(errorOOB),"\n",
" RMSE 0.632Boot=\t", sqrt(error632B),"\n",
" RMSE 0.632+Boot=\t", sqrt(error632masB),"\n")
```












